package learning.lda;

import java.io.BufferedReader;
import java.io.FileReader;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;

public class LDAModel {
	// All ids are zero-based
	private String[] idToNoun;
	private String[] idToVerb;
	private Map<String, Integer> nounToId;
	private Map<String, Integer> verbToId;
	
	// [i][j] = for verb i, Pr(topic j) V x T
	private double[][] topicDistPerVerb;
	// [i][j] = for topic i, Pr(noun j) T x N
	private double[][] nounDistPerTopic;
	
	private LDAModel() {};
	
	public int getNounCount() {
		return idToNoun.length;
	}
	
	public int getVerbCount() {
		return idToVerb.length;
	}
	
	public int getTopicCount() {
		return nounDistPerTopic.length;
	}
	
	public String getVerb(int vid) {
		return idToVerb[vid];
	}
	
	public String getNoun(int nid) {
		return idToNoun[nid];
	}
	
	public double getPrTopicForVerb(int tid, String verb) {
		if(!verbToId.containsKey(verb)) {
			return 0;
		}
		return topicDistPerVerb[verbToId.get(verb)][tid];
	}
	
	public double getPrTopicForVerb(int tid, int vid) {
		return topicDistPerVerb[vid][tid];
	}

	public double getPrNounForTopic(String noun, int tid) {
		if(!nounToId.containsKey(noun)) {
			return 0;
		}
		return nounDistPerTopic[tid][nounToId.get(noun)];
	}
	
	public double getPrNounForTopic(int nid, int tid) {
		return nounDistPerTopic[tid][nid];
	}
	
	/**
	 * Load LDA Model from baseDir
	 * @param baseDir - contains files created by data.preprocess.TrainSetToLDAFormatConverter
	 * and two more files - the trained models generated by MCMC.R:
	 * 1. topicDistPerVerb.txt
	 * 2. nounDistPerTopic.txt
	 */
	public static LDAModel loadModel(String baseDir) throws Exception {
		if(!baseDir.endsWith("/")) {
			baseDir += "/";
		}
		
		LDAModel model = new LDAModel();
		
		// Load noun mapping
		model.nounToId = new HashMap<String, Integer>();
		BufferedReader nounReader = new BufferedReader(new FileReader(baseDir + "nounIdx.txt"));
		String line = nounReader.readLine();
		while(line != null) {
			model.nounToId.put(line.trim(), model.nounToId.size());
			line = nounReader.readLine();
		}
		nounReader.close();
		
		// Load verb mapping
		model.verbToId = new HashMap<String, Integer>();
		BufferedReader verbReader = new BufferedReader(new FileReader(baseDir + "verbIdx.txt"));
		line = verbReader.readLine();
		while(line != null) {
			model.verbToId.put(line.trim(), model.verbToId.size());
			line = verbReader.readLine();
		}
		verbReader.close();

		int verbCount = model.verbToId.size();
		int nounCount = model.nounToId.size();

		System.out.println("Number of nouns = " + nounCount);
		System.out.println("Number of verbs = " + verbCount);
		
		// Reverse mapping for verbs and nouns
		model.idToNoun = new String[nounCount];
		for(Entry<String, Integer> entry : model.nounToId.entrySet()) {
			model.idToNoun[entry.getValue()] = entry.getKey();
		}
		
		model.idToVerb = new String[verbCount];
		for(Entry<String, Integer> entry : model.verbToId.entrySet()) {
			model.idToVerb[entry.getValue()] = entry.getKey();
		}
		
		System.out.println("Verb and Noun mappings loaded.");
		
		// Count # topics
		int topicCount = 0;
		BufferedReader nounDistPerTopicReader = new BufferedReader(new FileReader(baseDir + "nounDistPerTopic.txt"));
		line = nounDistPerTopicReader.readLine();
		while(line != null) {
			topicCount++;
			line = nounDistPerTopicReader.readLine();
		}
		nounDistPerTopicReader.close();

		System.out.println("Number of topics = " + topicCount);
		
		// Read nounDistPerTopic
		model.nounDistPerTopic = new double[topicCount][nounCount];
		nounDistPerTopicReader = new BufferedReader(new FileReader(baseDir + "nounDistPerTopic.txt"));
		line = nounDistPerTopicReader.readLine();
		int row = 0;
		while(line != null) {
			String[] toks = line.split("\t");
			for(int col = 0; col < nounCount; col++) {
				model.nounDistPerTopic[row][col] = Double.parseDouble(toks[col]);
			}
			row++;
			line = nounDistPerTopicReader.readLine();
		}
		nounDistPerTopicReader.close();
		
		System.out.println("Loaded nounDistPerTopic");
		
		// Read topicDistPerVerb
		model.topicDistPerVerb = new double[verbCount][topicCount];
		BufferedReader topicDistPerVerbReader = new BufferedReader(new FileReader(baseDir + "topicDistPerVerb.txt"));
		line = topicDistPerVerbReader.readLine();
		row = 0;
		while(line != null) {
			String[] toks = line.split("\t");
			for(int col = 0; col < topicCount; col++) {
				model.topicDistPerVerb[row][col] = Double.parseDouble(toks[col]);
			}
			row++;
			line = topicDistPerVerbReader.readLine();
		}
		topicDistPerVerbReader.close();
		System.out.println("Loaded topicDistPerVerb");
		
		return model;
	}
}
